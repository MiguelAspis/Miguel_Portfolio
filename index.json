[{
    "title": "Various NLP tasks done with state-of-the-art models",
    "date": "",
    "description": "Streamlit web app that is able to perform a range of NLP tasks using state-of-the-art models from the huggingface inference api",
    "body": "Table of Contents  Table of Contents Introduction Sentiment Analysis with DistillBert English-Portuguese Translation with transformer Text summarization - BART  Introduction This project was done mainly to learn the basics of streamlit, huggingface\u0026rsquo;s inference api and heroku app deployment and as such it isn\u0026rsquo;t very technically complex. Since the actual implementation is so basic due to the use of the pre-trained and fine-tuned models available at huggingface hub I have decided to write more in depth about the models used for each task.\nFollowing are the tasks and the respective models used:\n Sentiment Analysis - DistillBERT English-Portuguese Translation - transformer Text summarization - BART  For you to understand the content of these papers you will need to know beforehand how a transformer works, good resources for that include Transformers from scratch by Peter Bloem and Annotated Transformer by harvardnlp.\nMoreover it is also useful to have a firm grasping on how the BERT model works, although I will give a overview of the model.\nSentiment Analysis with DistillBert Firstly we have the sentiment analysis task, which aims at classifying sentences given its affective states. In this specific case we classify polarity, basically if the sentence is positive or negative.\nFor this task the model chosen was DistillBERT available at huggingface hub, but to understand DistillBert we must first understand the base BERT model.\nBERT is a large pre-trained language model that can be easily fine-tuned for a variety of different downstream tasks, achieving great performance in a number of them.\nThe great revolution brought by BERT was the fact that it is bi-directional (the B in Bert stands for that), which means it can look both left and right (before and after the current token in the sentence). This is done using a masked language model (MLM). In pre-training, the MLM randomly masks some of the tokens from the input, and the objective is to predict the original word based only on its context, allowing the model to learn the context of all words on the sentence. It can also understand sentence relationships, which was achieved by using yet another pre-training objective, next sentence prediction.\nFor each example in pre-training 2 sentences were fed to the model as input, A and B, where 50% of the time B was the actual next sentence in the text and the other 50% of the time it was a randomly sampled sentence from the corpus. More information about BERT, including the model architecture and the results can be found in the original paper.\nDistillBERT is a smaller, more efficient version of the BERT model, that has significanlty less parameters and is faster at inference time. This is achieved by applying a few different techniques.\nThe first of which is knowledge distillation, consisting of a smaller model - the student - being trained to reproduce the behaviour of a larger model, or ensemble of models - the teacher -\nThe student is then trained using cross-entropy between the student\u0026rsquo;s output and the teacher\u0026rsquo;s output. In the DistillBERT case, the final training objective is a linear combination of this distillation loss and the supervised learning loss (masked language modeling described above) and a cosine embedding loss, used to better align the student and teacher hidden state vectors. DistillBERT has the same general architecture as BERT but with fewer layers and to initialize the student network the researchers took 1 layer out of 2 from the teacher network, allowing for faster convergence (only possible due to the 2 networks having the same dimensions). The resulting model has 40% fewer parameters, is 60% faster and achieves 97% performance in downstream tasks compared to the original BERT model.\nEnglish-Portuguese Translation with transformer The model page only says it used a transformer model, with no further information on which transformer architecture was used all I can do from there is refer to the already mentioned resources for understanding transformers.\nText summarization - BART For the text summarization task the model chosen was BART available in huggingface models The BART model combines both Bidirectional (BERT) and autoregressive (GPT) transformers, training it by corrupting text with a arbitrary noising function and then learning a model to reconstruct the original input.\nBidirectional - looks at both directions in the text(missing tokens are predicted independently so it can\u0026rsquo;t easily generate text)\nAutoregressive - left-to-right, only looks at past tokens(can\u0026rsquo;t learn bidirectional interactions).\\\nBART generalizes both BERT and GPT and also has a key advantage in the fact that it can apply arbitrary noising on the input text, increasing its flexibility.\nThe architecture is based on 2 components, first a bidirectional encoder(BERT-like) with 6 layers that is responsible for receiving the corrupted input and encoding it, the output of this block is then fed to the second component, a auto-regressive decoder(GPT-like) used to calculate the likelihood of the original document.\nIn the pre-training phase a number of different text transformations are used before feeding the text to the model.\n Token Masking random tokens are sampled and replaced with \u0026ldquo;[MASK]\u0026rdquo; elements. Token Deletion Random tokens are deleted from the input. In contrast to token masking, the model must decide which positions are missing inputs. Text Infilling A number(a span)is sampled from a Poisson distribution, and each span is replaced with a single [MASK] token. this teaches the model to predict how many tokens are missing from a span. Sentence Permutation randomly shuffles sentences(defined by full-stops) Document Rotation A token is chosen uniformly at random, and the document is rotated so that it begins with that token. This task trains the model to identify the start of the document.  Then for each downstream task a different fine-tuning routine is adopted. Each of these noising regimes is then compared to a number of SOTA models, more about the results,fine-tuning and tasks can be read on the paper.\n",
    "ref": "/Miguel_Portfolio/blog/nlp-tasks/"
  },{
    "title": "About",
    "date": "",
    "description": "",
    "body": "Hi my name is Miguel Aspis, I\u0026rsquo;m a data scientist with experience in using deep learning to solve hard problems in a variety of contexts. My knowledge in physics allows me to look at some problems in a fresh perspective and find unique solutions.\nI feel passionate about everything science-related and specially about how physics and AI can solve society\u0026rsquo;s biggest problems.\nI\u0026rsquo;m currently working as a freelance data scientist and am always up for a challenge. Reach out through the contact page or directly through aspismiguel2@gmail.com to connect!\n",
    "ref": "/Miguel_Portfolio/about/"
  },{
    "title": "Image Captioning",
    "date": "",
    "description": "Image Captioning done using EfficientNetB0 and Transformers",
    "body": "Image Captioning project done using Keras and Tensorflow and trained o the flickr8kdataset applying visual attention using EfficientNetB0 to extract image embeddings and then training a transformer model based on the original architecture to provide captions. More can be read in the notebook located on the project\u0026rsquo;s github repo\n",
    "ref": "/Miguel_Portfolio/blog/image-captioning/"
  },{
    "title": "Sunspot Forecasting",
    "date": "",
    "description": "Sunspot forecasting using a number of different simple architectures",
    "body": "Time series forecasting project done on the monthly mean sunspot number 1749-2018 dataset using Tensroflow and Keras Sequential API to design a number of very simple models to test on this problem, the goal was not to get the performance possible but to recall the workflow of working with time series data and how to do forecasting with it. More can be read in the notebook located on the project\u0026rsquo;s github repo\n",
    "ref": "/Miguel_Portfolio/blog/sunspot-forecast/"
  },{
    "title": "Music Classification",
    "date": "",
    "description": "Music Classification using a CNN and a LSTM on the Marsyas dataset",
    "body": "Music classification project with the intent of classifying different songs based on their genre using the Marsyas dataset and using 2 architectures, a small convolutional neural network and a recurrent neural network with LSTM cells. Accompanied by audio preprocessing routine which was done on each music sample to be able to feed it to the NNs using the librosa library. The whole project can be seen on the github repo\n",
    "ref": "/Miguel_Portfolio/blog/music-classification/"
  },{
    "title": "Simple Chatbot",
    "date": "",
    "description": "Chatbot developed in python using keras, Tensoflow, nltk and tkinter for the GUI",
    "body": "Simple chatbot developed in Python trained using nltk for Natural language processing and Tensorflow for training the model, using a simple feedforward neural network. The GUI was programmed using tkinter. More can be seen in the project\u0026rsquo;s github repo\n",
    "ref": "/Miguel_Portfolio/blog/chatbot/"
  },{
    "title": "Movie Recommender System",
    "date": "",
    "description": "Recommender system developed on the imdb dataset",
    "body": "Notebook with exploratory data analysis, seeing relationships and interesting facts in the data, with some visualizations and development of 2 basic recommender systems, one based on correlation between movies and the other using the K Nearest Neighbor algorithm. More can be read on the notebook available at the github repo\n",
    "ref": "/Miguel_Portfolio/blog/film-recommender/"
  },{
    "title": "Basic Image Classification",
    "date": "",
    "description": "Simple image classification on CIFAR-10 dataset with Keras and Tensorflow",
    "body": "Basic Image classification A project done using a simple CNN architecture to do image classification on the CIFAR-10 dataset.\nSteps of the process include:\n Importing the data One-hot enconding it Defining 1st basic CNN using Keras high-level Sequential API Training and evaluating Defining a bit bigger model Training and evaluating Comparing both and concluding  more can be read on the project\u0026rsquo;s github repo\n",
    "ref": "/Miguel_Portfolio/blog/image-classification/"
  },{
    "title": "Uber data visualization",
    "date": "",
    "description": "Data visualization project performed on Uber trips dataset",
    "body": "Data visualization project on dataset with uber trips data on New York city in the year 2014. Some interesting information could be gathered regarding costumer\u0026rsquo;s habits and patterns. One of such visualizations can be seen here:\nMore of these can be seen on the github repo\n",
    "ref": "/Miguel_Portfolio/blog/uber-viz/"
  },{
    "title": "Contact",
    "date": "",
    "description": "",
    "body": "",
    "ref": "/Miguel_Portfolio/contact/"
  }]
